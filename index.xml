<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Code Chronicle</title>
    <link>https://code-chronicle.github.io/</link>
    <description>Recent content on Code Chronicle</description>
    <generator>Hugo -- 0.127.0</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 08:43:51 +0900</lastBuildDate>
    <atom:link href="https://code-chronicle.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS ECR Multi Architecture Images</title>
      <link>https://code-chronicle.github.io/aws/aws-ecr-multi-architecture-images/</link>
      <pubDate>Fri, 16 Aug 2024 08:43:51 +0900</pubDate>
      <guid>https://code-chronicle.github.io/aws/aws-ecr-multi-architecture-images/</guid>
      <description>Amazon Elastic Container Registry(AWS ECR)는 AWS에서 제공하는 container image를 저장하고 관리할 수 있는 서비스입니다. 이 서비스의 멀티 아키텍처(Multi-Architecture) 기능을 사용하면 서로 다른 CPU 아키텍처(예: x86, ARM 등)를 사용하는 시스템에서도 동일한 container image를 실행할 수 있습니다. 즉, 하나의 container image를 생성하면, 이를 다양한 하드웨어 환경에서 호환되게끔 지원해 주는 기능을 제공한다는 의미입니다. 이를 통해 개발자는 하나의 이미지로 다양한 환경을 지원할 수 있어 운영 효율성이 높아집니다. 아래의 예제에서는 Docker 명령어를 사용하였습니다.
AWS ECR Multi Architecture Image Build (buildx) Multi Architecture Image를 빌드하는 첫 번째 방법은 Docker Buildx 명령어를 사용하는 것입니다.</description>
    </item>
    <item>
      <title>Kubernetes Service Type - Loadbalancer</title>
      <link>https://code-chronicle.github.io/kubernetes/kubernetes-service-loadbalancer/</link>
      <pubDate>Thu, 25 Jul 2024 08:57:23 +0900</pubDate>
      <guid>https://code-chronicle.github.io/kubernetes/kubernetes-service-loadbalancer/</guid>
      <description>Kubernetes는 애플리케이션을 컨테이너화하고 관리하는 강력한 도구입니다. 그 중에서도 Service는 클러스터 내의 애플리케이션을 네트워킹하는 데 중요한 역할을 합니다. Kubernetes 서비스는 ClusterIP, NodePort, LoadBalancer, ExternalName 네 가지 유형이 있습니다. 이번 글에서는 Kubernetes Service의 한 종류인 Loadbalancer에 대해 자세히 알아보겠습니다.
LoadBalancer란? LoadBalancer 타입은 퍼블릭 클라우드 환경에서 사용할 수 있으며, 클라우드 환경의 로드 밸런서를 생성하여 외부 트래픽을 Kubernetes 클러스터 내부의 서비스로 라우팅하는 데 사용됩니다. 이러한 로드 밸런서는 클러스터 외부에서 접근할 수 있는 IP 주소와 포트를 제공하여 외부 트래픽을 내부 서비스로 효율적으로 분배합니다.</description>
    </item>
    <item>
      <title>Kubernetes Service Type - NodePort</title>
      <link>https://code-chronicle.github.io/kubernetes/kubernetes-service-nodeport/</link>
      <pubDate>Tue, 16 Jul 2024 18:56:08 +0900</pubDate>
      <guid>https://code-chronicle.github.io/kubernetes/kubernetes-service-nodeport/</guid>
      <description>Kubernetes는 애플리케이션을 컨테이너화하고 관리하는 강력한 도구입니다. 그 중에서도 Service는 클러스터 내의 애플리케이션을 네트워킹하는 데 중요한 역할을 합니다. Kubernetes 서비스는 ClusterIP, NodePort, LoadBalancer, ExternalName 네 가지 유형이 있습니다. 이번 글에서는 Kubernetes Service의 한 종류인 NodePort에 대해 자세히 알아보겠습니다.
NodePort란? NodePort는 클러스터 외부에서 Kubernetes 클러스터 내부로 트래픽을 전달할 수 있는 가장 간단한 방법 중 하나입니다. NodePort는 클러스터의 각 노드에서 고정된 포트를 열어, 이 포트를 통해 외부 트래픽을 특정 POD로 라우팅합니다.
주요 특징 NodePort는 Kubernetes 클러스터 내 노드의 특정 포트(30000-32767)를 열어 트래픽을 수신합니다.</description>
    </item>
    <item>
      <title>Argo Rollouts Introduction</title>
      <link>https://code-chronicle.github.io/kubernetes/argo-rollouts-introduction/</link>
      <pubDate>Sun, 14 Jul 2024 15:03:22 +0900</pubDate>
      <guid>https://code-chronicle.github.io/kubernetes/argo-rollouts-introduction/</guid>
      <description>일반적으로 Kubernetes 클러스터 상에 애플리케이션을 구동하고 상태를 관리하기 위해서 Deployment1 리소스를 활용합니다. Deployment에는 애플리케이션의 목표 상태(i.e. 애플리케이션 Pod의 개수, 애플리케이션의 버전 등)가 저장되어 있어, 목표 상태와 클러스터 상의 실제 상태를 일치하도록 관리합니다. 이는 Kubernetes에서 기본으로 제공되는 리소스로서 매우 유용하지만, 새로운 버전의 애플리케이션을 배포할 때 몇가지의 문제를 마주치게 됩니다.
배포 진행 속도를 컨트롤할 수 없음 Blue/Green, Canary 등의 고도화된 배포 전략을 제공하지 않음 배포 과정에 문제가 생겼을 때, 수동으로 문제를 감지하고 롤백해야 함 물론 쿠버네티스 기본 리소스만으로도 위와 같은 문제들을 해결할 수 있지만, 이는 복잡한 아키텍처 설계를 필요로 합니다.</description>
    </item>
    <item>
      <title>Kubernetes Service Type - ClusterIP</title>
      <link>https://code-chronicle.github.io/kubernetes/kubernetes-service-clusterip/</link>
      <pubDate>Fri, 12 Jul 2024 20:48:24 +0900</pubDate>
      <guid>https://code-chronicle.github.io/kubernetes/kubernetes-service-clusterip/</guid>
      <description>Kubernetes는 애플리케이션을 컨테이너화하고 관리하는 강력한 도구입니다. 그 중에서도 Service는 클러스터 내의 애플리케이션을 네트워킹하는 데 중요한 역할을 합니다. Kubernetes 서비스는 ClusterIP, NodePort, LoadBalancer, ExternalName 네 가지 유형이 있습니다. 이번 글에서는 Kubernetes Service의 한 종류인 ClusterIP에 대해 자세히 알아보겠습니다.
ClusterIP란? ClusterIP는 Kubernetes Service의 기본 유형입니다. 이 유형은 클러스터 내부에서만 접근 가능한 가상 IP 주소를 할당하여, Pod 간의 통신을 용이하게 합니다. ClusterIP는 외부에서 접근할 수 없기 때문에 클러스터 내부에서의 서비스 디스커버리와 서버 간 통신 목적으로 사용됩니다.</description>
    </item>
    <item>
      <title>Getting Started with Keda</title>
      <link>https://code-chronicle.github.io/kubernetes/getting-started-with-keda/</link>
      <pubDate>Wed, 03 Jul 2024 09:00:46 +0900</pubDate>
      <guid>https://code-chronicle.github.io/kubernetes/getting-started-with-keda/</guid>
      <description>KEDA: Kubernetes Event-Driven Autoscaling 소개 클라우드 네이티브 애플리케이션은 동적으로 변하는 트래픽과 워크로드를 효율적으로 처리하기 위해 자동 확장이 필수적입니다. Kubernetes는 기본적인 자동 확장 기능을 제공하지만, KEDA(Kubernetes Event-Driven Autoscaling)는 보다 세밀하고 이벤트 기반의 자동 확장을 가능하게 해줍니다. 이번 포스팅에서는 KEDA의 개념, 주요 기능, 그리고 사용 사례에 대해 알아보겠습니다.
KEDA란 무엇인가? KEDA(Kubernetes Event-Driven Autoscaling)는 Kubernetes와 함께 작동하도록 설계된 이벤트 기반 자동 확장 플랫폼입니다. KEDA는 Kubernetes 클러스터에서 애플리케이션을 안정적이고 확장 가능하게 실행할 수 있도록 지원합니다.</description>
    </item>
  </channel>
</rss>
